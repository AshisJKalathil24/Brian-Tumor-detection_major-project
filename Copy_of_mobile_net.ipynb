{
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "version": "3.6.4",
      "file_extension": ".py",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "name": "python",
      "mimetype": "text/x-python"
    },
    "kaggle": {
      "accelerator": "none",
      "dataSources": [
        {
          "sourceId": 2645886,
          "sourceType": "datasetVersion",
          "datasetId": 1608934
        }
      ],
      "dockerImageVersionId": 30407,
      "isInternetEnabled": false,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": false
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# MRI Brain Scans\n",
        "\n",
        "## Analyzed via a Convolutional Neural Network, and using Transfer Learning relying on MobileNet_V2\n",
        "\n",
        "The machine learning models presented below were jointly created by:\n",
        "\n",
        "1. **Brianna Chrisman, Ph.D.** *(BioEngineering/BioInformatics, Stanford 2022)*\n",
        "2. **Stanislav Jabuka, Ph.D.** *(Mathematics, Michigan State, 2002)*\n",
        "\n",
        "Two models are presented, namely\n",
        "\n",
        "-  `model_CNN` - A Convolutional Neural Network built from first principles, and\n",
        "-  `model_MobileNetV2` - A model created using *Transfer Learning*, starting with the Keras application MoblineNetV2. For more information about the latter, please consult https://keras.io/api/applications/\n",
        "    \n",
        "The two models are trained for 30 and 50 epochs respecively, after which their accuracy on training and testing MRI scans is as follows:\n",
        "\n",
        "-  Accuracy on *training* data: **99.46%** and **99.39%** respectively.\n",
        "-  Accuracy on *testing* data:  **97.48%** and **95.35%** respectively.\n",
        "\n",
        "Visual representations of the accuracy of both models are given in terms of their *graphs* (with epochs as the input variable) and their *Confusion Matrices*."
      ],
      "metadata": {
        "id": "YjLctbTdaFot"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Preparing the training and testing data\n",
        "\n",
        "This first cell prepares numpy arrays to contain the training and testing images for both models. The input layer for MobileNetV2 has shape (None, 224, 224, 3), prompting us to convert the provided MRI scans to RGB (3 color channels) images of size 224x224. For the CNN model we transform the input images to grayscale pictures of size 150x150, thus creating arrays of shape (None, 150, 150).  "
      ],
      "metadata": {
        "id": "BLWpRb2vaFo8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ilH2CQ1cahVM",
        "outputId": "5fe3f672-3e94-4338-ea88-0b2a688d5d25"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "import os\n",
        "import random\n",
        "\n",
        "train_path = '/content/drive/MyDrive/archive (3)/Training'\n",
        "test_path = '/content/drive/MyDrive/archive (3)/Testing'\n",
        "\n",
        "def y_2binary(n):\n",
        "    z=np.zeros((4), dtype=int)\n",
        "    z[n]=1\n",
        "    return z\n",
        "\n",
        "\n",
        "### Get a list of subdirectories of the train_path\n",
        "sub_dirs = os.listdir(train_path)\n",
        "\n",
        "\n",
        "### We shall map names of the subdirectories to numerical values 0, 1, ..., using a dictionary.\n",
        "output_dictionary = {}\n",
        "for i in range(len(sub_dirs)):\n",
        "    output_dictionary.update({sub_dirs[i]: i})\n",
        "\n",
        "print('The subdirectories are',sub_dirs,'.\\n')\n",
        "\n",
        "\n",
        "### Create empty lists for training/testing data, since we don't know how big they will be.\n",
        "x_train_CNN = []\n",
        "x_test_CNN = []\n",
        "\n",
        "x_train_MobileNetV2 = []\n",
        "x_test_MobileNetV2 = []\n",
        "\n",
        "### The training/testing output data is the same for both models.\n",
        "y_train = []\n",
        "y_test = []\n",
        "\n",
        "### Calculate the number of training samples in each subdirectory, find the total number of training samples.\n",
        "### Convert images to size (150,150) for CNN model, and to size (224,224,3) for MobilenetV2 model. Convert\n",
        "### the lists to arrays, and store array in x_train.\n",
        "\n",
        "for dir in sub_dirs:\n",
        "    sub_dir_path_train = train_path + '/' + dir\n",
        "    file_counter_train=0\n",
        "    for path in os.listdir(sub_dir_path_train):\n",
        "        x=os.path.join(sub_dir_path_train,path)\n",
        "        if os.path.isfile(x):\n",
        "            file_counter_train+=1\n",
        "\n",
        "            image_CNN = cv2.resize(cv2.imread(x,cv2.IMREAD_GRAYSCALE),(150,150))\n",
        "            image_MobileNetV2 = cv2.resize(cv2.imread(x),(224,224))\n",
        "\n",
        "            x_train_CNN.append(image_CNN)\n",
        "            x_train_MobileNetV2.append(image_MobileNetV2)\n",
        "            y_train.append(y_2binary(output_dictionary[dir]))\n",
        "\n",
        "    print('The training directory',dir,'has',file_counter_train,'samples.')\n",
        "print()\n",
        "\n",
        "### Calculate the number of testing samples in each subdirectory, find the total number of testing samples.\n",
        "### Convert images to size (224,224,3), then convert them to an np.array, and store array in x_test.\n",
        "\n",
        "for dir in sub_dirs:\n",
        "    sub_dir_path_test = test_path + '/' + dir\n",
        "    file_counter_test=0\n",
        "    for path in os.listdir(sub_dir_path_test):\n",
        "        x=os.path.join(sub_dir_path_test,path)\n",
        "        if os.path.isfile(x):\n",
        "            file_counter_test+=1\n",
        "\n",
        "            image_CNN = cv2.resize(cv2.imread(x,cv2.IMREAD_GRAYSCALE),(150,150))\n",
        "            image_MobileNetV2 = cv2.resize(cv2.imread(x),(224,224))\n",
        "\n",
        "            x_test_CNN.append(image_CNN)\n",
        "            x_test_MobileNetV2.append(image_MobileNetV2)\n",
        "            y_test.append(y_2binary(output_dictionary[dir]))\n",
        "\n",
        "    print('The testing directory',dir,'has',file_counter_test,'samples.')\n",
        "print()\n",
        "\n",
        "### Convert the now fully populated lists to numpy arrays.\n",
        "x_train_CNN = np.array(x_train_CNN)/255.0\n",
        "x_test_CNN = np.array(x_test_CNN)/255.0\n",
        "x_train_CNN  = x_train_CNN[:,:,:,np.newaxis]\n",
        "x_test_CNN  =  x_test_CNN[:,:,:,np.newaxis]\n",
        "\n",
        "x_train_MobileNetV2 = np.array(x_train_MobileNetV2)/255.0\n",
        "x_test_MobileNetV2 = np.array(x_test_MobileNetV2)/255.0\n",
        "\n",
        "y_train = np.array(y_train)\n",
        "y_test = np.array(y_test)\n",
        "\n",
        "\n",
        "### Print information summary, and a sample training and test image.\n",
        "print()\n",
        "print('The shape of x_train_CNN is',x_train_CNN.shape,'.')\n",
        "print('The shape of x_test_CNN is',x_test_CNN.shape,'.\\n')\n",
        "print('The shape of x_train_MobileNetV2 is',x_train_MobileNetV2.shape,'.')\n",
        "print('The shape of x_test_MobileNetV2 is',x_test_MobileNetV2.shape,'.\\n')\n",
        "print('The shape of y_train is',y_train.shape,'.')\n",
        "print('The shape of y_test is',y_test.shape,'.\\n')\n",
        "\n",
        "\n",
        "print('The total number of training samples is',len(y_train),'.')\n",
        "print('The total number of testing samples is',len(y_test),'.\\n')\n",
        "\n",
        "\n",
        "n1 = random.randint(0,len(y_train))\n",
        "plt.imshow(x_train_CNN[n1], cmap='gray')\n",
        "plt.title('Sample Trainig Scan')\n",
        "plt.show()\n",
        "\n",
        "print()\n",
        "\n",
        "n2 = random.randint(0,len(x_test_CNN))\n",
        "plt.imshow(x_test_CNN[n2], cmap='gray')\n",
        "plt.title('Sample Testing Scan')\n",
        "plt.show()"
      ],
      "metadata": {
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u6LBz5AsaFo9",
        "outputId": "2e401119-f5b3-4f11-ade1-e4cdb206d3e6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The subdirectories are ['pituitary', 'glioma', 'meningioma', 'notumor'] .\n",
            "\n",
            "The training directory pituitary has 1457 samples.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Creating the CNN model\n",
        "\n",
        "The next cell creates the Convolutional Neural Network model `model_CNN`. It is a sequential model, consisting of 4 `Conv2D` layers, with increasing numbers of kernels, and decreasing kernel sizes. MaxPooling and Dropout layers are inserted after each `Conv2D` layer. The model is completed by flattening the output of the convolutional layers, and adding a final dense layer with 4 neurons. A summary of the model is presented after its creation."
      ],
      "metadata": {
        "id": "bhn2bG5MaFo-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### Creating the CNN Model\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from keras.layers import Input, Dense, InputLayer, Flatten, Conv2D, MaxPooling2D, Dropout\n",
        "from keras.models import Model, Sequential\n",
        "from keras import metrics\n",
        "\n",
        "model_CNN = Sequential()\n",
        "model_CNN.add(InputLayer(input_shape=(150,150,1)))\n",
        "\n",
        "model_CNN.add(Conv2D(filters=32, kernel_size=(5,5), activation='relu'))\n",
        "model_CNN.add(MaxPooling2D(pool_size=(2,2)))\n",
        "model_CNN.add(Dropout(0.25))\n",
        "\n",
        "model_CNN.add(Conv2D(filters=64, kernel_size=(4,4), activation='relu'))\n",
        "model_CNN.add(MaxPooling2D(pool_size=(2,2)))\n",
        "model_CNN.add(Dropout(0.25))\n",
        "\n",
        "model_CNN.add(Conv2D(filters=128, kernel_size=(3,3), activation='relu'))\n",
        "model_CNN.add(MaxPooling2D(pool_size=(2,2)))\n",
        "model_CNN.add(Dropout(0.25))\n",
        "\n",
        "model_CNN.add(Conv2D(filters=256, kernel_size=(2,2), activation='relu'))\n",
        "model_CNN.add(MaxPooling2D(pool_size=(2,2)))\n",
        "model_CNN.add(Dropout(0.25))\n",
        "\n",
        "model_CNN.add(Flatten())\n",
        "model_CNN.add(Dense(2048, activation='relu'))\n",
        "model_CNN.add(Dropout(0.25))\n",
        "\n",
        "model_CNN.add(Dense(4, activation='softmax'))\n",
        "\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=0.001, beta_1=0.9, beta_2=0.99)\n",
        "model_CNN.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "model_CNN.summary()"
      ],
      "metadata": {
        "trusted": true,
        "id": "pHkkyOaiaFo-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training the CNN model\n",
        "\n",
        "We train the CNN model for 30 epochs on the prepared training data."
      ],
      "metadata": {
        "id": "X1R5yeXgaFo_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "import math\n",
        "\n",
        "t1=time.time()\n",
        "history_CNN = model_CNN.fit(x_train_CNN, y_train, batch_size = 64, epochs = 30)\n",
        "model_CNN.save('CNN_30epochs')\n",
        "t2=time.time()\n",
        "print('The training of 30 epochs of the CNN model took',round((t2-t1)/60),'minutes.')"
      ],
      "metadata": {
        "trusted": true,
        "id": "W9M1ISrDaFo_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Creating the MobileNet_V2 transfer model\n",
        "\n",
        "The next cell creates the trasnfer model `model_MobileNetV2` by starting with `MobileNet_V2`. We tag on a new output layer - a dense layer with 4 neurons. Only the paramters of the last layer are trainable. A summary of the created model is displayed."
      ],
      "metadata": {
        "id": "fSahEvfPaFo_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "##### Create the Transfer Learning model from Keras application MobileNetV2.\n",
        "import sys\n",
        "from keras.layers import Dense, Flatten\n",
        "from keras.models import Model\n",
        "from keras.applications.mobilenet_v2 import MobileNetV2\n",
        "\n",
        "model_temp = MobileNetV2(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
        "model_temp.trainable = False\n",
        "x = model_temp.output\n",
        "x = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
        "x = Dense(4, activation='softmax')(x)\n",
        "\n",
        "model_MobileNetV2 = Model(inputs=model_temp.input, outputs=x)\n",
        "\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=0.001, beta_1=0.9, beta_2=0.99)\n",
        "model_MobileNetV2.compile(loss='categorical_crossentropy', optimizer=optimizer,\n",
        "                     metrics=['accuracy'])\n",
        "\n",
        "model_MobileNetV2.summary()"
      ],
      "metadata": {
        "trusted": true,
        "id": "CvhG4NMZaFo_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training the MobilNet_V2 transfer model\n",
        "\n",
        "Next we train the transfer model for 50 epochs on the prepared training data."
      ],
      "metadata": {
        "id": "QB03AgEhaFpA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "t3=time.time()\n",
        "history_MobileNetV2 = model_MobileNetV2.fit(x_train_MobileNetV2, y_train, epochs=50, batch_size=64)\n",
        "model_MobileNetV2.save('MobileNetV2_50epochs')\n",
        "t4=time.time()\n",
        "print()\n",
        "print('The training of 50 epochs of the Transfer Learning model took',round((t4-t3)/60),'minutes.')"
      ],
      "metadata": {
        "trusted": true,
        "id": "ujQFzVFkaFpA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Accuracy and loss on testing data\n",
        "\n",
        "We test the accuracy and compute the loss of both models on the provided testing data."
      ],
      "metadata": {
        "id": "ZDYnaWJoaFpA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "val_loss_CNN, val_accuracy_CNN = model_CNN.evaluate(x_test_CNN, y_test)\n",
        "val_loss_MobileNetV2, val_accuracy_MobileNetV2 = model_MobileNetV2.evaluate(x_test_MobileNetV2, y_test)\n",
        "\n",
        "print()\n",
        "print('The loss of the CNN model is',round(val_loss_CNN,4),' while its accuracy on testing datais ',round(100*val_accuracy_CNN,2),'%.')\n",
        "print('The loss of the Transfer Learning model is',round(val_loss_MobileNetV2,4),' while its accuracy on testing datais ',round(100*val_accuracy_MobileNetV2,2),'%.')\n"
      ],
      "metadata": {
        "trusted": true,
        "id": "CLQLVusUaFpA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Accuracy and loss plots\n",
        "The next two cells present graphs of the accuracy and loss, viewed as functions of the epochs.  "
      ],
      "metadata": {
        "id": "Te0EzPBSaFpA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(history_CNN.history[\"loss\"],c=\"red\")\n",
        "plt.plot(history_CNN.history[\"accuracy\"],c=\"green\")\n",
        "plt.title(\"Loss and Accuracy in the CNN Model\")\n",
        "plt.ylabel(\"Loss/Accuracy\")\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.legend(['loss','accuracy'])\n",
        "plt.show()"
      ],
      "metadata": {
        "trusted": true,
        "id": "4yrDTMaZaFpA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(history_MobileNetV2.history[\"loss\"],c=\"red\")\n",
        "plt.plot(history_MobileNetV2.history[\"accuracy\"],c=\"green\")\n",
        "plt.title(\"Loss and Accuracy in the Transfer Learning Model\")\n",
        "plt.ylabel(\"Loss/Accuracy\")\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.legend(['loss','accuracy'])\n",
        "plt.show()"
      ],
      "metadata": {
        "trusted": true,
        "id": "EwtWNdF_aFpA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
        "\n",
        "predictions_CNN = np.argmax(model_CNN.predict(x_test_CNN),axis=1)\n",
        "predictions_MobileNetV2 = np.argmax(model_MobileNetV2.predict(x_test_MobileNetV2),axis=1)\n",
        "test=np.argmax(y_test,axis=1)"
      ],
      "metadata": {
        "trusted": true,
        "id": "iAP6gQyXaFpB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Confusion Matrices\n",
        "\n",
        "The next two cells give further graphical representation of the accurcy of both models on the testing data, by displaying their **Confusion Matrices**."
      ],
      "metadata": {
        "id": "-cpqkdQBaFpB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "disp_CNN = ConfusionMatrixDisplay(confusion_matrix(test, predictions_CNN))\n",
        "disp_CNN.plot()\n",
        "disp_CNN.ax_.set_title(\"Confusion matrix for the CNN model.\")\n",
        "plt.show()"
      ],
      "metadata": {
        "trusted": true,
        "id": "-EkP3l3EaFpB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "disp_MobileNetV2 = ConfusionMatrixDisplay(confusion_matrix(test, predictions_MobileNetV2))\n",
        "disp_MobileNetV2.plot()\n",
        "disp_MobileNetV2.ax_.set_title(\"Confusion matrix for the Transfer Learning model.\")\n",
        "plt.show()"
      ],
      "metadata": {
        "trusted": true,
        "id": "3rfnLzGfaFpB"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}